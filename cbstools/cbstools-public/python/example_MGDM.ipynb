{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cbstools as cbs\n",
    "from os.path import join\n",
    "import os\n",
    "import nibabel as nb\n",
    "import numpy as np\n",
    "import glob as glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chris/mipav/plugins/atlases/brain-segmentation-prior3.0/\n",
      "/home/chris/Documents/code/python/cbstools-python/ToloplogyLUT/\n"
     ]
    }
   ],
   "source": [
    "current_dir = os.getcwd() #current directy of this notebook\n",
    "\n",
    "data_dir='/home/chris/Documents/code/python/cbstools-python/test-python'\n",
    "out_dir='/home/chris/Documents/code/python/cbstools-python/test-python/out'\n",
    "\n",
    "t1_fname='t1map_stripped.nii.gz'\n",
    "uni_fname='uni_stripped.nii.gz'\n",
    "pre_fname='filters.nii.gz'\n",
    "\n",
    "atlas_file = 'brain-atlas-3.0.3.txt'\n",
    "\n",
    "print(cbs.ATLAS_DIR) #as defined in your defaults file\n",
    "print(cbs.TOPOLOGY_LUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<jcc.JCCEnv object at 0x7f90127f2e10>\n",
      "Java virtual machine successfully started.\n"
     ]
    }
   ],
   "source": [
    "#cbs=reload(cbs)\n",
    "cbs.setup_JVM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you for choosing the MGDM segmentation from the cbstools for your brain segmentation needs\n",
      "Sit back and relax, let the magic of algorithms happen...\n",
      "Atlas file: /home/chris/mipav/plugins/atlases/brain-segmentation-prior3.0/brain-atlas-3.0.3.txt\n",
      "Topology LUT durectory: /home/chris/Documents/code/python/cbstools-python/ToloplogyLUT/\n",
      "\n",
      "Input files and filetypes:\n",
      "  1  ['/home/chris/Documents/code/python/cbstools-python/test-python/uni_stripped.nii.gz', 'MP2RAGE7T']\n",
      "Executing MGDM on your inputs\n",
      "Don't worry, the magic is happening!\n",
      "/home/chris/Documents/code/python/cbstools-python/test-python/out/uni_stripped_seg_cjs.nii.gz\n",
      "Data stored in: /home/chris/Documents/code/python/cbstools-python/test-python/out\n",
      "Execution completed\n"
     ]
    }
   ],
   "source": [
    "cbs.MGDMBrainSegmentation([[join(data_dir,uni_fname),\"MP2RAGE7T\"]],\n",
    "                             output_dir=out_dir,atlas_file=None, topology_lut_dir=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you for choosing the MGDM segmentation from the cbstools for your brain segmentation needs\n",
      "Sit back and relax, let the magic of algorithms happen...\n",
      "\n",
      "Atlas file: /home/chris/mipav/plugins/atlases/brain-segmentation-prior3.0/brain-atlas-3.0.3.txt\n",
      "Topology LUT durectory: /home/chris/Documents/code/python/cbstools-python/ToloplogyLUT/\n",
      "\n",
      "Input files and filetypes:\n",
      "  1  ['/home/chris/Documents/code/python/cbstools-python/test-python/uni_stripped.nii.gz', 'MP2RAGE7T']\n",
      "Input files and filetypes:\n",
      "  2  ['/home/chris/Documents/code/python/cbstools-python/test-python/filters.nii.gz', 'Filters']\n",
      "Executing MGDM on your inputs\n",
      "Don't worry, the magic is happening!\n",
      "/home/chris/Documents/code/python/cbstools-python/test-python/out/uni_stripped_seg_cjs.nii.gz\n",
      "Data stored in: /home/chris/Documents/code/python/cbstools-python/test-python/out\n",
      "Execution completed\n"
     ]
    }
   ],
   "source": [
    "cbs=reload(cbs)\n",
    "cbs.MGDMBrainSegmentation([[join(data_dir,uni_fname),\"MP2RAGE7T\"],[join(data_dir,pre_fname),\"Filters\"]],\n",
    "                             output_dir=out_dir,atlas_file=None, topology_lut_dir=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have not chosen a valid contrast for your metric_contrast_name, please choose from: \n",
      "DWIFA3T, DWIMD3T, T1map9T, Mp2rage9T, T1map7T, Mp2rage7T, PV, Filters, T1pv, Mprage3T, T1map3T, Mp2rage3T, HCPT1w, HCPT2w, NormMPRAGE\n"
     ]
    }
   ],
   "source": [
    "## test priors updating\n",
    "cbs=reload(cbs)\n",
    "seg_file = glob.glob(os.path.join(out_dir,\"*_seg_cjs.nii.gz\"))\n",
    "seg_files = [seg_file[0],seg_file[0]]\n",
    "met_files = [join(data_dir,uni_fname),join(data_dir,uni_fname)]\n",
    "met_con=\"Mprage3T\"\n",
    "[medians,spreads]=cbs.generate_group_intensity_priors(seg_files,met_files,\"bob\",\n",
    "                                                                      join(cbs.ATLAS_DIR,atlas_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "medians"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- after here is mockup for creating a scriptable change in priors --- (it works!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def seg_erode(seg_d, iterations=1, background_idx = 1,\n",
    "              structure=None, min_vox_count = 5,seg_null_value = 0,\n",
    "             VERBOSE=False):\n",
    "    # erode indices (integers) to identify \"core\" structure\n",
    "    # XXX might need to limit erosion here and loop myself\n",
    "    # default erosion structure is 3,1 (which is not super restrictive, and should work for most)\n",
    "    # seg null value is int value that is assigned to voxels that were eroded from the segmentation\n",
    "    import scipy.ndimage as ndi\n",
    "    import numpy as np\n",
    "    \n",
    "    if structure is None:\n",
    "        structure = ndi.morphology.generate_binary_structure(3, 1)\n",
    "    if seg_null_value == 0:\n",
    "        seg_shrunk_d = np.zeros_like(seg_d)\n",
    "        temp_d = np.zeros_like(seg_d)\n",
    "    else:\n",
    "        seg_shrunk_d = np.ones_like(seg_d)*seg_null_value\n",
    "        temp_d = np.ones_like(seg_d)*seg_null_value    \n",
    "    \n",
    "    seg_idxs = np.unique(seg_d)\n",
    "  \n",
    "    for seg_idx in seg_idxs:\n",
    "        print(seg_idx),\n",
    "        if (background_idx is not None) and (background_idx == seg_idx):\n",
    "            seg_shrunk_d[seg_d==seg_idx] = seg_idx #just set the value to the bckgrnd value, and be done with it\n",
    "            if VERBOSE:\n",
    "                print(\"[bckg]\"),\n",
    "        else:\n",
    "            temp_d[seg_d==seg_idx] = 1\n",
    "            for idx in range(0, iterations): #messy, does not exit the loop when already gone too far.\n",
    "                temp_temp_d = ndi.binary_erosion(temp_d, iterations=1, structure=structure)\n",
    "                if np.sum(temp_temp_d) >= min_vox_count:\n",
    "                    temp_d = temp_temp_d\n",
    "                    if VERBOSE:\n",
    "                        print(\"[y]\"),\n",
    "                else:\n",
    "                    if VERBOSE:\n",
    "                        print(\"[no]\"),\n",
    "            seg_shrunk_d[temp_d==1] = seg_idx\n",
    "            temp_d[:,:,:] = seg_null_value\n",
    "            if VERBOSE:\n",
    "                print(seg_idx)\n",
    "    print(\"\")\n",
    "    return seg_shrunk_d\n",
    "\n",
    "\n",
    "\n",
    "def extract_metrics_from_seg(seg_d, metric_d, norm_data = True,\n",
    "                             background_idx = 1, seg_null_value = 0,\n",
    "                             percentile_top_bot = [75,25],\n",
    "                             return_normed_metric_d=False):\n",
    "    #returns np matrix of indices, and one of median, and percentiles\n",
    "    #norm_data = true first zscores all of the data other than the background\n",
    "    import numpy as np\n",
    "    import scipy\n",
    "    seg_idxs = np.unique(seg_d)\n",
    "    res = np.zeros((len(seg_idxs),3))\n",
    "    \n",
    "    if norm_data: # rescale the data to 0\n",
    "        if background_idx is not None: #we need to exclude the background data from the norming\n",
    "            metric_d[seg_d!=background_idx] = (metric_d[seg_d!=background_idx] - np.min(metric_d[seg_d!=background_idx])) / (np.max(metric_d[seg_d!=background_idx]) - np.min(metric_d[seg_d!=background_idx]))\n",
    "        else:\n",
    "            metric_d = (metric_d - np.min(metric_d)) / (np.max(metric_d)-np.min(metric_d))\n",
    "        \n",
    "    for idx,seg_idx in enumerate(seg_idxs):\n",
    "        if (background_idx is not None) and ((seg_idx == background_idx) or (seg_idx == seg_null_value)):\n",
    "            res[idx,:] = [0,0,0]\n",
    "        else:\n",
    "            d_1d = np.ndarray.flatten(metric_d[seg_d == seg_idx])\n",
    "            res[idx,:] = [np.mean(d_1d),\n",
    "                          np.percentile(d_1d,np.max(percentile_top_bot)),\n",
    "                          np.percentile(d_1d,np.min(percentile_top_bot))]\n",
    "    if return_normed_metric_d:\n",
    "        return seg_idxs,res,metric_d\n",
    "    else:\n",
    "        return seg_idxs,res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seg indices: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 14,  14,  14, ..., 132, 132, 132]),\n",
       " array([ 86,  87,  87, ..., 103, 103, 103]),\n",
       " array([60, 51, 58, ..., 57, 58, 59]))"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load the output segmentatinb.Nifti1Image(d_seg_ero,a_seg).to_filename(os.path.join(out_dir,\"d_seg_ero.nii.gz\"))on file\n",
    "seg_files = glob.glob(os.path.join(out_dir,\"*_seg_cjs.nii.gz\"))\n",
    "# point it back at the input file, extract values from \n",
    "seg_file=seg_files[0]\n",
    "img=nb.load(seg_file)\n",
    "d_seg = img.get_data()\n",
    "a_seg = img.affine\n",
    "\n",
    "d_metric = nb.load(join(data_dir,uni_fname)).get_data()\n",
    "seg_null_value = 0\n",
    "\n",
    "print(\"seg indices: \"),\n",
    "np.unique(d_seg)\n",
    "np.where(d_seg==50)\n",
    "#d_seg[70,66,43]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 8 10 11 12 13 14 17 18 20 25 26 27 30 31 32 33 34 35 36 37 38 39 40 41 43 46 47 48 50 \n"
     ]
    }
   ],
   "source": [
    "#erode the seg file\n",
    "d_seg_ero = seg_erode(d_seg,background_idx = 1, seg_null_value = seg_null_value)\n",
    "nb.Nifti1Image(d_seg_ero,a_seg).to_filename(os.path.join(out_dir,\"d_seg_ero.nii.gz\"))\n",
    "\n",
    "#extract the values from each index\n",
    "[seg_idxs,seg_stats,d_metric_norm] = extract_metrics_from_seg(d_seg_ero,d_metric,seg_null_value=seg_null_value,\n",
    "                                                             return_normed_metric_d=True)\n",
    "nb.Nifti1Image(d_metric_norm,a_seg).to_filename(os.path.join(out_dir,\"d_metric_norm.nii.gz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  8 10 11 12 13 14 17 18 20 25 26 27 30 31 32 33 34 35 36 37 38 39 40\n",
      " 41 43 46 47 48 50]\n",
      "[ 0.          0.          0.          0.22563398  0.08410583  0.08987724\n",
      "  0.16868669  0.20622344  0.48463598  0.17966332  0.2674751   0.46390796\n",
      "  0.45047241  0.46238199  0.39889997  0.34720081  0.48333097  0.46535555\n",
      "  0.35564139  0.36721775  0.56746542  0.54524189  0.68753362  0.65726626\n",
      "  0.78753018  0.7920326   0.69178802  0.75529468  0.8249054   0.83420277\n",
      "  0.06309689]\n",
      "[ 0.1         0.1         0.1         0.24719246  0.1         0.1\n",
      "  0.18838063  0.18998904  0.1         0.1         0.30075012  0.21800042\n",
      "  0.32179964  0.29512179  0.17577323  0.18397549  0.1         0.10100538\n",
      "  0.15619811  0.15573829  0.13367768  0.13912316  0.12773302  0.1336633\n",
      "  0.1         0.1         0.11633818  0.1         0.1         0.1         0.1       ]\n"
     ]
    }
   ],
   "source": [
    "## explicitly set our median and spread variables for priors, just makes it easier to put into df later\n",
    "\n",
    "MIN_QUART_DIFF = 0.10\n",
    "prior_medians=seg_stats[:,0]\n",
    "prior_quart_diffs=np.squeeze(np.abs(np.diff(seg_stats[:,1:3])))\n",
    "\n",
    "# fill in prior_quart_diffs that are below a certain value??\n",
    "prior_quart_diffs[prior_quart_diffs<MIN_QUART_DIFF] = MIN_QUART_DIFF\n",
    "print(seg_idxs)\n",
    "print(prior_medians)\n",
    "print(prior_quart_diffs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## parse the atlas file to get the lut and the intensity priors of interest\n",
    "new_atlas_file = 'brain-atlas-3.0.3_cjs.txt'\n",
    "lut_idx=np.zeros(2).astype(int)\n",
    "con_idx=np.zeros(2).astype(int)\n",
    "contrast_name = 'Mprage3T'\n",
    "\n",
    "#identify the start and stop locations for the LUT and the intensity priors of interest\n",
    "fp = open(os.path.join(cbs.ATLAS_DIR,atlas_file))\n",
    "for i, line in enumerate(fp):\n",
    "    if \"Structures:\" in line: #this is the beginning of the LUT\n",
    "        lut_idx[0] = i\n",
    "    if \"Topology Atlas:\" in line: #the end of the LUT\n",
    "        lut_idx[1] = i-2\n",
    "    if \"Intensity Prior:\" in line:\n",
    "        if contrast_name in line:\n",
    "            con_idx[0] = i\n",
    "fp.close()\n",
    "\n",
    "lut=pd.read_csv(os.path.join(cbs.ATLAS_DIR,atlas_file),sep=\"\\t+\",\n",
    "                skiprows=lut_idx[0]+1,nrows=lut_idx[1]-lut_idx[0],engine='python',\n",
    "                names=[\"Index\",\"Type\"])\n",
    "\n",
    "con_idx[1] = len(lut) #total number is the same length as the lut\n",
    "priors=pd.read_csv(os.path.join(cbs.ATLAS_DIR,atlas_file),sep=\"\\t+\",\n",
    "                   skiprows=con_idx[0]+1,nrows=con_idx[1],engine='python',\n",
    "                   names=[\"Median\",\"Spread\",\"Weight\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## create a new dataframe and populate with our new values\n",
    "# could also add intelligence here, to only push it to 1/2 of the difference etc (next release...)\n",
    "priors_new = pd.DataFrame.copy(priors)\n",
    "for idx in lut.Index:\n",
    "    priors_new[lut[\"Index\"]==idx] = [prior_medians[seg_idxs==idx], prior_quart_diffs[seg_idxs==idx],1]\n",
    "priors_new.head()\n",
    "priors_new_string = priors_new.to_csv(sep=\"\\t\",header=False,float_format=\"%.2f\")\n",
    "priors_new_string_lines = priors_new_string.split(\"\\n\")[0:-1] #convert to list of lines, cut the last empty '' line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New atlas file written to: /home/chris/mipav/plugins/atlases/brain-segmentation-prior3.0/brain-atlas-3.0.3_cjs.txt\n"
     ]
    }
   ],
   "source": [
    "#identify the start and stop locations for the LUT and the intensity priors of interest\n",
    "fp = open(os.path.join(cbs.ATLAS_DIR,atlas_file))\n",
    "fp_new = open(os.path.join(cbs.ATLAS_DIR,new_atlas_file),\"w\")\n",
    "ii=0\n",
    "#only replace the lines that we changed\n",
    "for i, line in enumerate(fp):\n",
    "    if i > con_idx[0] and i<con_idx[1]+con_idx[0]:\n",
    "        fp_new.write(priors_new_string_lines[ii]+\"\\n\")\n",
    "        ii+=1\n",
    "    else:\n",
    "        fp_new.write(line)\n",
    "fp.close()\n",
    "fp_new.close()\n",
    "print(\"New atlas file written to: \" + fp_new.name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
