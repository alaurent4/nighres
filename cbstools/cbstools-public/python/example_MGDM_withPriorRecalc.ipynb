{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cbstools as cbs\n",
    "from os.path import join\n",
    "import os\n",
    "import nibabel as nb\n",
    "import numpy as np\n",
    "import glob as glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  0.5       ,  0.26894142])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbs.filter_sigmoid(np.array([1000000,.002,.0015]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chris/mipav/plugins/atlases/brain-segmentation-prior3.0/\n",
      "/home/chris/Documents/code/python/cbstools-python/ToloplogyLUT/\n"
     ]
    }
   ],
   "source": [
    "## MD SIGMOID FUNCTION PARAMS:\n",
    "#sigmoid must scale from 0 to 1, hopefully\n",
    "# center x at 0.002 and slope at 0.0005\n",
    "\n",
    "# y(+infin)=1, (-infin)=0, .002=.5, .0015=1/4\n",
    "# p=((x-.002)/.0005)\n",
    "# y=1/(1+exp(-p))\n",
    "\n",
    "current_dir = os.getcwd() #current directy of this notebook\n",
    "\n",
    "data_dir='/home/chris/Documents/code/python/cbstools-python/test-python'\n",
    "out_dir='/home/chris/Documents/code/python/cbstools-python/test-python/out'\n",
    "\n",
    "t1_fname='t1map_stripped.nii.gz'\n",
    "uni_fname='uni_stripped.nii.gz'\n",
    "pre_fname='filters.nii.gz'\n",
    "\n",
    "atlas_file = 'brain-atlas-3.0.3.txt'\n",
    "\n",
    "print(cbs.ATLAS_DIR) #as defined in your defaults file\n",
    "print(cbs.TOPOLOGY_LUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<jcc.JCCEnv object at 0x7f8576998d38>\n",
      "Java virtual machine successfully started.\n"
     ]
    }
   ],
   "source": [
    "#cbs=reload(cbs)\n",
    "cbs.setup_JVM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you for choosing the MGDM segmentation from the cbstools for your brain segmentation needs\n",
      "Sit back and relax, let the magic of algorithms happen...\n",
      "\n",
      "Atlas file: /home/chris/mipav/plugins/atlases/brain-segmentation-prior3.0/brain-atlas-3.0.3.txt\n",
      "Topology LUT durectory: /home/chris/Documents/code/python/cbstools-python/ToloplogyLUT/\n",
      "\n",
      "Input files and filetypes:\n",
      "  1  ['/home/chris/Documents/code/python/cbstools-python/test-python/uni_stripped.nii.gz', 'MP2RAGE7T']\n",
      "data orientation: ('L', 'P', 'S') slice settings: AXIAL\n",
      "mgdm orientation: [[ 0.  1.]\n",
      " [ 1.  1.]\n",
      " [ 2.  1.]]\n",
      "data orientation: [[ 0. -1.]\n",
      " [ 1. -1.]\n",
      " [ 2.  1.]]\n",
      "Executing MGDM on your inputs\n",
      "Don't worry, the magic is happening!\n",
      "/home/chris/Documents/code/python/cbstools-python/test-python/out/uni_stripped_seg_cjs.nii.gz\n",
      "Data stored in: /home/chris/Documents/code/python/cbstools-python/test-python/out\n",
      "Execution completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ..., \n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]],\n",
       " \n",
       "        [[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ..., \n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]],\n",
       " \n",
       "        [[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ..., \n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]],\n",
       " \n",
       "        ..., \n",
       "        [[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ..., \n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]],\n",
       " \n",
       "        [[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ..., \n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]],\n",
       " \n",
       "        [[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         ..., \n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 1, 1, 1]]], dtype=uint32),\n",
       " array([[  -1.24657536,    0.        ,    0.        ,  107.21218872],\n",
       "        [   0.        ,   -1.25114942,    0.        ,  182.94389343],\n",
       "        [   0.        ,    0.        ,    1.24657536, -230.70652771],\n",
       "        [   0.        ,    0.        ,    0.        ,    1.        ]]),\n",
       " <nibabel.nifti1.Nifti1Header at 0x7f85336b7d50>)"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbs=reload(cbs)\n",
    "cbs.MGDMBrainSegmentation([[join(data_dir,uni_fname),\"MP2RAGE7T\"]],\n",
    "                             output_dir=out_dir,atlas_file=None, topology_lut_dir=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you for choosing the MGDM segmentation from the cbstools for your brain segmentation needs\n",
      "Sit back and relax, let the magic of algorithms happen...\n",
      "\n",
      "Atlas file: /home/chris/mipav/plugins/atlases/brain-segmentation-prior3.0/brain-atlas-3.0.3.txt\n",
      "Topology LUT durectory: /home/chris/Documents/code/python/cbstools-python/ToloplogyLUT/\n",
      "\n",
      "Input files and filetypes:\n",
      "  1  ['/home/chris/Documents/code/python/cbstools-python/test-python/uni_stripped.nii.gz', 'MP2RAGE7T']\n",
      "Input files and filetypes:\n",
      "  2  ['/home/chris/Documents/code/python/cbstools-python/test-python/filters.nii.gz', 'Filters']\n",
      "Executing MGDM on your inputs\n",
      "Don't worry, the magic is happening!\n",
      "/home/chris/Documents/code/python/cbstools-python/test-python/out/uni_stripped_seg_cjs.nii.gz\n",
      "Data stored in: /home/chris/Documents/code/python/cbstools-python/test-python/out\n",
      "Execution completed\n"
     ]
    }
   ],
   "source": [
    "cbs=reload(cbs)\n",
    "cbs.MGDMBrainSegmentation([[join(data_dir,uni_fname),\"MP2RAGE7T\"],[join(data_dir,pre_fname),\"Filters\"]],\n",
    "                             output_dir=out_dir,atlas_file=None, topology_lut_dir=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def seg_erode(seg_d, iterations=1, background_idx = 1,\n",
    "              structure=None, min_vox_count = 5,seg_null_value = 0,\n",
    "             VERBOSE=False):\n",
    "    # erode indices (integers) to identify \"core\" structure\n",
    "    # XXX might need to limit erosion here and loop myself\n",
    "    # default erosion structure is 3,1 (which is not super restrictive, and should work for most)\n",
    "    # seg null value is int value that is assigned to voxels that were eroded from the segmentation\n",
    "    import scipy.ndimage as ndi\n",
    "    import numpy as np\n",
    "    \n",
    "    if structure is None:\n",
    "        structure = ndi.morphology.generate_binary_structure(3, 1)\n",
    "    if seg_null_value == 0:\n",
    "        seg_shrunk_d = np.zeros_like(seg_d)\n",
    "        temp_d = np.zeros_like(seg_d)\n",
    "    else:\n",
    "        seg_shrunk_d = np.ones_like(seg_d)*seg_null_value\n",
    "        temp_d = np.ones_like(seg_d)*seg_null_value    \n",
    "    \n",
    "    seg_idxs = np.unique(seg_d)\n",
    "    \n",
    "    if seg_null_value in seg_idxs:\n",
    "        print(\"Shit, your null value is also an index. This will not work.\")\n",
    "        print(\"Set it to a suitably strange value that is not already an index. {0,999}\")\n",
    "        return None\n",
    "    \n",
    "    for seg_idx in seg_idxs:\n",
    "        print(seg_idx),\n",
    "        if (background_idx is not None) and (background_idx == seg_idx):\n",
    "            seg_shrunk_d[seg_d==seg_idx] = seg_idx #just set the value to the bckgrnd value, and be done with it\n",
    "            if VERBOSE:\n",
    "                print(\"[bckg]\"),\n",
    "        else:\n",
    "            temp_d[seg_d==seg_idx] = 1\n",
    "            for idx in range(0, iterations): #messy, does not exit the loop when already gone too far.\n",
    "                temp_temp_d = ndi.binary_erosion(temp_d, iterations=1, structure=structure)\n",
    "                if np.sum(temp_temp_d) >= min_vox_count:\n",
    "                    temp_d = temp_temp_d\n",
    "                    if VERBOSE:\n",
    "                        print(\"[y]\"),\n",
    "                else:\n",
    "                    if VERBOSE:\n",
    "                        print(\"[no]\"),\n",
    "            seg_shrunk_d[temp_d==1] = seg_idx\n",
    "            temp_d[:,:,:] = seg_null_value\n",
    "            if VERBOSE:\n",
    "                print(seg_idx)\n",
    "    print(\"\")\n",
    "    return seg_shrunk_d\n",
    "\n",
    "\n",
    "\n",
    "def extract_metrics_from_seg(seg_d, metric_d, norm_data = True,\n",
    "                             background_idx = 1, seg_null_value = 0,\n",
    "                             percentile_top_bot = [75,25],\n",
    "                             return_normed_metric_d=False):\n",
    "    #returns np matrix of indices, and one of median, and percentiles\n",
    "    #norm_data = true first zscores all of the data other than the background\n",
    "    import numpy as np\n",
    "    import scipy\n",
    "    seg_idxs = np.unique(seg_d)\n",
    "    res = np.zeros((len(seg_idxs),3))\n",
    "    \n",
    "    if norm_data: # rescale the data to 0\n",
    "        if background_idx is not None: #we need to exclude the background data from the norming\n",
    "            metric_d[seg_d!=background_idx] = (metric_d[seg_d!=background_idx] - np.min(metric_d[seg_d!=background_idx])) / (np.max(metric_d[seg_d!=background_idx]) - np.min(metric_d[seg_d!=background_idx]))\n",
    "        else:\n",
    "            metric_d = (metric_d - np.min(metric_d)) / (np.max(metric_d)-np.min(metric_d))\n",
    "        \n",
    "    for idx,seg_idx in enumerate(seg_idxs):\n",
    "        if (background_idx is not None) and ((seg_idx == background_idx) or (seg_idx == seg_null_value)):\n",
    "            res[idx,:] = [0,0,0]\n",
    "        else:\n",
    "            d_1d = np.ndarray.flatten(metric_d[seg_d == seg_idx])\n",
    "            res[idx,:] = [np.mean(d_1d),\n",
    "                          np.percentile(d_1d,np.max(percentile_top_bot)),\n",
    "                          np.percentile(d_1d,np.min(percentile_top_bot))]\n",
    "    if return_normed_metric_d:\n",
    "        return seg_idxs,res,metric_d\n",
    "    else:\n",
    "        return seg_idxs,res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seg indices: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 14,  14,  14, ..., 132, 132, 132]),\n",
       " array([ 86,  87,  87, ..., 103, 103, 103]),\n",
       " array([60, 51, 58, ..., 57, 58, 59]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load the output segmentatinb.Nifti1Image(d_seg_ero,a_seg).to_filename(os.path.join(out_dir,\"d_seg_ero.nii.gz\"))on file\n",
    "seg_files = glob.glob(os.path.join(out_dir,\"*_seg_cjs.nii.gz\"))\n",
    "# point it back at the input file, extract values from \n",
    "seg_file=seg_files[0]\n",
    "img=nb.load(seg_file)\n",
    "d_seg = img.get_data()\n",
    "a_seg = img.affine\n",
    "\n",
    "d_metric = nb.load(join(data_dir,uni_fname)).get_data()\n",
    "seg_null_value = 0\n",
    "\n",
    "print(\"seg indices: \"),\n",
    "np.unique(d_seg)\n",
    "np.where(d_seg==50)\n",
    "#d_seg[70,66,43]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146, 174, 146)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.header.get_data_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 8 10 11 12 13 14 17 18 20 25 26 27 30 31 32 33 34 35 36 37 38 39 40 41 43 46 47 48 50\n"
     ]
    }
   ],
   "source": [
    "#erode the seg file\n",
    "cbs=reload(cbs)\n",
    "d_seg_ero = cbs.seg_erode(d_seg,background_idx = 1, seg_null_value = seg_null_value)\n",
    "nb.Nifti1Image(d_seg_ero,a_seg).to_filename(os.path.join(out_dir,\"d_seg_ero.nii.gz\"))\n",
    "\n",
    "#extract the values from each index\n",
    "[seg_idxs,seg_stats,d_metric_norm] = cbs.extract_metrics_from_seg(d_seg_ero,d_metric,seg_null_value=seg_null_value,\n",
    "                                                             return_normed_metric_d=True)\n",
    "nb.Nifti1Image(d_metric_norm,a_seg).to_filename(os.path.join(out_dir,\"d_metric_norm.nii.gz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  8 10 11 12 13 14 17 18 20 25 26 27 30 31 32 33 34 35 36 37 38 39 40\n",
      " 41 43 46 47 48 50]\n",
      "[ 0.39642414  2.48996043  0.          0.22563398  0.08410583  0.08987724\n",
      "  0.16868669  0.20622344  0.48463598  0.17966332  0.2674751   0.46390796\n",
      "  0.45047241  0.46238199  0.39889997  0.34720081  0.48333097  0.46535555\n",
      "  0.35564139  0.36721775  0.56746542  0.54524189  0.68753362  0.65726626\n",
      "  0.78753018  0.7920326   0.69178802  0.75529468  0.8249054   0.83420277\n",
      "  0.06309689]\n",
      "[ 0.48501778  0.1         0.1         0.24719246  0.1         0.1\n",
      "  0.18838063  0.18998904  0.1         0.1         0.30075012  0.21800042\n",
      "  0.32179964  0.29512179  0.17577323  0.18397549  0.1         0.10100538\n",
      "  0.15619811  0.15573829  0.13367768  0.13912316  0.12773302  0.1336633\n",
      "  0.1         0.1         0.11633818  0.1         0.1         0.1         0.1       ]\n"
     ]
    }
   ],
   "source": [
    "## explicitly set our median and spread variables for priors, just makes it easier to put into df later\n",
    "\n",
    "MIN_QUART_DIFF = 0.10\n",
    "prior_medians=seg_stats[:,0]\n",
    "prior_quart_diffs=np.squeeze(np.abs(np.diff(seg_stats[:,1:3])))\n",
    "\n",
    "# fill in prior_quart_diffs that are below a certain value??\n",
    "prior_quart_diffs[prior_quart_diffs<MIN_QUART_DIFF] = MIN_QUART_DIFF\n",
    "print(seg_idxs)\n",
    "print(prior_medians)\n",
    "print(prior_quart_diffs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## OLD WAY\n",
    "## parse the atlas file to get the lut and the intensity priors of interest\n",
    "\n",
    "#identify the start and stop locations for the LUT and the intensity priors of interest\n",
    "fp = open(os.path.join(cbs.ATLAS_DIR,atlas_file))\n",
    "for i, line in enumerate(fp):\n",
    "    if \"Structures:\" in line: #this is the beginning of the LUT\n",
    "        lut_idx = i\n",
    "        lut_rows=map(int,[line.split()[1]])[0]\n",
    "#    if \"Topology Atlas:\" in line: #the end of the LUT #OR you could use the value in the line?\n",
    "#        lut_idx[1] = i-2\n",
    "    if \"Intensity Prior:\" in line:\n",
    "        if contrast_name in line:\n",
    "            con_idx = i\n",
    "fp.close()\n",
    "\n",
    "lut=pd.read_csv(os.path.join(cbs.ATLAS_DIR,atlas_file),sep=\"\\t+\",\n",
    "                skiprows=lut_idx+1,nrows=lut_rows,engine='python',\n",
    "                names=[\"Index\",\"Type\"])\n",
    "\n",
    "#con_idx[1] = len(lut) #total number is the same length as the lut\n",
    "priors=pd.read_csv(os.path.join(cbs.ATLAS_DIR,atlas_file),sep=\"\\t+\",\n",
    "                   skiprows=con_idx+1,nrows=lut_rows,engine='python',\n",
    "                   names=[\"Median\",\"Spread\",\"Weight\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cbs=reload(cbs)\n",
    "new_atlas_file = 'brain-atlas-3.0.3_cjs.txt'\n",
    "contrast_name = 'Mprage3T'\n",
    "[con_idx,lut_rows,lut,priors]=cbs.extract_lut_priors_from_atlas(new_atlas_file,contrast_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## create a new dataframe and populate with our new values\n",
    "# could also add intelligence here, to only push it to 1/2 of the difference etc (next release...)\n",
    "priors_new = pd.DataFrame.copy(priors)\n",
    "for idx in lut.Index:\n",
    "    priors_new[lut[\"Index\"]==idx] = [prior_medians[seg_idxs==idx], prior_quart_diffs[seg_idxs==idx],1]\n",
    "priors_new.head()\n",
    "priors_new_string = priors_new.to_csv(sep=\"\\t\",header=False,float_format=\"%.2f\")\n",
    "priors_new_string_lines = priors_new_string.split(\"\\n\")[0:-1] #convert to list of lines, cut the last empty '' line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -0.43690311, -0.95      ,  0.04563398, -0.14589417,\n",
       "        -0.14012276, -0.06131331, -0.02377656, -0.01536402, -0.32033668,\n",
       "        -0.2325249 , -0.12609204, -0.07952759, -0.06761801, -0.29110003,\n",
       "        -0.34279919, -0.20666903, -0.22464445, -0.27435861, -0.26278225,\n",
       "        -0.21253458, -0.23475811, -0.09246638, -0.12273374, -0.16246982,\n",
       "        -0.1579674 , -0.23821198, -0.16470532, -0.1050946 , -0.09579723]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#keep track of what we did with the old and new priors\n",
    "#assume that everything is in the correct order... if it is not, things are not so good!\n",
    "#this allows looping across individuals or successive segmentations, but not currently both\n",
    "\n",
    "all_Ss_priors_list_median=np.vstack((priors.Median,priors_new.Median))\n",
    "all_Ss_priors_list_spread=np.vstack((priors.Spread,priors_new.Spread))\n",
    "\n",
    "np.diff(all_Ss_priors_list_median,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New atlas file written to: /home/chris/mipav/plugins/atlases/brain-segmentation-prior3.0/brain-atlas-3.0.3_cjs.txt\n"
     ]
    }
   ],
   "source": [
    "# write out the newly altered priors list\n",
    "fp = open(os.path.join(cbs.ATLAS_DIR,atlas_file))\n",
    "fp_new = open(os.path.join(cbs.ATLAS_DIR,new_atlas_file),\"w\")\n",
    "ii=0\n",
    "#only replace the lines that we changed\n",
    "for i, line in enumerate(fp):\n",
    "    if i > con_idx[0] and i<con_idx[1]+con_idx[0]:\n",
    "        fp_new.write(priors_new_string_lines[ii]+\"\\n\")\n",
    "        ii+=1\n",
    "    else:\n",
    "        fp_new.write(line)\n",
    "fp.close()\n",
    "fp_new.close()\n",
    "print(\"New atlas file written to: \" + fp_new.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/chris/Documents/projects_working/2016_Brainhack/DWI_sample/CIC_dti_MD_sig.nii.gz'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## more testing, with FA and MD files\n",
    "cbs=reload(cbs)\n",
    "in_dir='/home/chris/Documents/projects_working/2016_Brainhack/DWI_sample'\n",
    "from os.path import join\n",
    "\n",
    "md_filt=cbs.filter_sigmoid(join(in_dir,'CIC_dti_MD.nii.gz'))\n",
    "cbs.niiSave(join(in_dir,'CIC_dti_MD_sig.nii.gz'),md_filt[0],affine=md_filt[1],header=md_filt[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you for choosing the MGDM segmentation from the cbstools for your brain segmentation needs\n",
      "Sit back and relax, let the magic of algorithms happen...\n",
      "\n",
      "Atlas file: /home/chris/mipav/plugins/atlases/brain-segmentation-prior3.0/brain-atlas-3.0.3.txt\n",
      "Topology LUT durectory: /home/chris/Documents/code/python/cbstools-python/ToloplogyLUT/\n",
      "\n",
      "Input files and filetypes:\n",
      "  1  ['/home/chris/Documents/projects_working/2016_Brainhack/DWI_sample/CIC_dti_FA.nii.gz', 'DWIFA3T']\n",
      "orientation: ('L', 'A', 'S') slice settings: AXIAL\n",
      "Input files and filetypes:\n",
      "  2  ['/home/chris/Documents/projects_working/2016_Brainhack/DWI_sample/CIC_dti_MD_sig.nii.gz', 'DWIMD3T']\n",
      "orientation: ('L', 'A', 'S') slice settings: AXIAL\n",
      "Executing MGDM on your inputs\n",
      "Don't worry, the magic is happening!\n",
      "/home/chris/Documents/projects_working/2016_Brainhack/DWI_sample/CIC_dti_FA_seg_cjs.nii.gz\n",
      "Data stored in: /home/chris/Documents/projects_working/2016_Brainhack/DWI_sample\n",
      "Execution completed\n"
     ]
    }
   ],
   "source": [
    "cbs=reload(cbs)\n",
    "con1_file = join(in_dir,'CIC_dti_FA.nii.gz')\n",
    "con2_file = join(in_dir,'CIC_dti_MD_sig.nii.gz')\n",
    "seg,aff,head = cbs.MGDMBrainSegmentation([[con1_file,'DWIFA3T'],[con2_file,'DWIMD3T']],\n",
    "                                  output_dir=in_dir,atlas_file=None, \n",
    "                                  topology_lut_dir=None,num_steps=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "OrientationError",
     "evalue": "Data array has fewer dimensions than orientation",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOrientationError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-368-2848f2edadca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#sform[2,2] = sform[2,2]*-1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mseg_flip\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maff_flip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflip_affine_data_orientation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mflipLR\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mflipAP\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mflipIS\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mseg_flip2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morientations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_orientation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maff_flip\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNifti1Image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morientations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_orientation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maff_flip\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maff_flip\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#img.set_sform(sform)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/chris/.local/lib/python2.7/site-packages/nibabel/orientations.pyc\u001b[0m in \u001b[0;36mapply_orientation\u001b[1;34m(arr, ornt)\u001b[0m\n\u001b[0;32m    156\u001b[0m     \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mornt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mt_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m         raise OrientationError('Data array has fewer dimensions than '\n\u001b[0m\u001b[0;32m    159\u001b[0m                                'orientation')\n\u001b[0;32m    160\u001b[0m     \u001b[1;31m# no coordinates can be dropped for applying the orientations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOrientationError\u001b[0m: Data array has fewer dimensions than orientation"
     ]
    }
   ],
   "source": [
    "cbs=reload(cbs)\n",
    "#sform = nb.load(join(in_dir,con1_file)).get_sform()\n",
    "#sform[2,2] = sform[2,2]*-1\n",
    "seg_flip, aff_flip = cbs.flip_affine_data_orientation(seg,aff,flipLR=False,flipAP=True,flipIS=False)\n",
    "seg_flip2 = nb.orientations.apply_orientation(seg,aff_flip)\n",
    "img=nb.Nifti1Image(nb.orientations.apply_orientation(seg,aff_flip),aff_flip)\n",
    "#img.set_sform(sform)\n",
    "img.to_filename(join(in_dir,\"test2.nii.gz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.]\n",
      " [ 1.  1.]\n",
      " [ 2. -1.]]\n",
      "[[ -1.99554968e+00   9.41075459e-02   9.44717824e-02   1.20489822e+02]\n",
      " [  9.39716771e-02   1.99778461e+00  -5.09611191e-03  -1.08620071e+02]\n",
      " [  9.46069360e-02   6.45936525e-04  -1.99776065e+00  -4.16052132e+01]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "ornt = nb.orientations.io_orientation(np.diag([-1, 1, 1, 1]).dot(aff)) #LAS\n",
    "print(ornt)\n",
    "print(aff)\n",
    "#t_aff = nb.orientations.inv_ornt_aff(ornt,np.shape(seg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.]\n",
      " [ 1. -1.]\n",
      " [ 2.  1.]]\n",
      "no good\n",
      "[[ -1.99554968e+00   9.41075459e-02   9.44717824e-02   1.20489822e+02]\n",
      " [  9.39716771e-02   1.99778461e+00  -5.09611191e-03   0.00000000e+00]\n",
      " [  9.46069360e-02   6.45936525e-04   1.99776065e+00  -4.16052132e+01]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   1.00000000e+00]]\n",
      "[[ 0.  1.]\n",
      " [ 1. -1.]\n",
      " [ 2.  1.]]\n",
      "[[   1.    0.    0.    0.]\n",
      " [   0.   -1.    0.  127.]\n",
      " [   0.    0.    1.    0.]\n",
      " [   0.    0.    0.    1.]]\n",
      "[[ -1.99554968e+00  -9.41075459e-02   9.44717824e-02   1.32441481e+02]\n",
      " [  9.39716771e-02  -1.99778461e+00  -5.09611191e-03   3.01718646e+02]\n",
      " [  9.46069360e-02  -6.45936525e-04   1.99776065e+00  -4.15231792e+01]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "from nibabel.orientations import io_orientation, inv_ornt_aff, apply_orientation, ornt_transform\n",
    "#mgdm_orient = nb.orientations.io_orientation(np.diag([1, 1, 1, 1]))\n",
    "ornt_input = io_orientation(aff)\n",
    "ornt_input2mgdm = nb.orientations.io_orientation(np.diag([-1, -1, 1, 1]).dot(aff)) #1 1 1 is RAS, -1 -1 1 LPS (mgdm default)\n",
    "print(ornt_input2mgdm)\n",
    "#ornt_input2mgdm[:,1]=ornt_input2mgdm[:,1]*ornt_input[:,1]\n",
    "if np.all(ornt == [[0, 1],\n",
    "                   [1, 1],\n",
    "                   [2, 1]]):  # already in LAS+\n",
    "    t_aff = np.eye(4)\n",
    "    print(\"All good\")\n",
    "else: \n",
    "    #ornt_input2mgdm[:,1]=ornt_input2mgdm[:,1]*-1\n",
    "    t_aff = inv_ornt_aff(ornt_input2mgdm, np.shape(seg))\n",
    "    print(\"no good\")\n",
    "print(aff)\n",
    "print(ornt_input2mgdm)\n",
    "print(t_aff)\n",
    "aff2[1,-1]=aff2[1,-1]+48\n",
    "aff_new = np.dot(aff, t_aff)\n",
    "print(aff_new)\n",
    "aff2=aff\n",
    "\n",
    "seg_flip = apply_orientation(seg, ornt_input2mgdm)\n",
    "nb.Nifti1Image(seg_flip,aff2).to_filename(join(in_dir,\"xxx_test2_flip.nii.gz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0. -1.]\n",
      " [ 1.  1.]\n",
      " [ 2.  1.]]\n",
      "[[ 0. -1.]\n",
      " [ 1. -1.]\n",
      " [ 2.  1.]]\n",
      "[[   1.    0.    0.    0.]\n",
      " [   0.   -1.    0.  127.]\n",
      " [   0.    0.    1.    0.]\n",
      " [   0.    0.    0.    1.]]\n",
      "[[ -1.99554968e+00   9.41075459e-02   9.44717824e-02   1.20489822e+02]\n",
      " [  9.39716771e-02   1.99778461e+00  -5.09611191e-03  -4.80000000e+01]\n",
      " [  9.46069360e-02   6.45936525e-04   1.99776065e+00  -4.16052132e+01]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   1.00000000e+00]]\n",
      "[[ -1.99554968e+00   9.41075459e-02   9.44717824e-02   1.20489822e+02]\n",
      " [  9.39716771e-02   1.99778461e+00  -5.09611191e-03  -8.90000000e+01]\n",
      " [  9.46069360e-02   6.45936525e-04   1.99776065e+00  -4.16052132e+01]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "#current try, with my stuffs...\n",
    "from nibabel.orientations import io_orientation, inv_ornt_aff, apply_orientation, ornt_transform\n",
    "\n",
    "ornt_orig = io_orientation(aff)\n",
    "ornt_mgdm = io_orientation(np.diag([-1, -1, 1, 1]).dot(aff)) #-1 -1 1 LPS (mgdm default); 1 1 1 is RAS\n",
    "ornt_chng = ornt_transform(ornt_mgdm,ornt_orig) #to get from MGDM to our original input\n",
    "#ornt_chng[:,1]=ornt_chng[:,1]*-1\n",
    "#t_aff = np.diag(np.append(ornt_chng[:,1],[1]))\n",
    "#aff_new = np.dot(aff, t_aff)\n",
    "print(ornt_orig)\n",
    "print(ornt_chng)\n",
    "print(t_aff)\n",
    "aff2 = np.copy(aff)\n",
    "aff2[1,-1]=aff2[1,-1]-41\n",
    "seg_flip = apply_orientation(seg, ornt_chng)\n",
    "img=nb.Nifti1Image(seg_flip,aff)\n",
    "img.update_header()\n",
    "img.to_filename(join(in_dir,\"xxx_test2_flip.nii.gz\"))\n",
    "print(aff)\n",
    "print(aff2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flirt_aff = [[0.9999988322,  -0.0008334219106,  0.001260845295,  0.02879772489],  \n",
    "[0.001064651508 , 0.9805542622,  -0.1962452202,  -3.774127818],  \n",
    "[-0.001072772206 , 0.1962463325,  0.9805540593,  -27.28980765],  \n",
    "[0,  0,  0,  1  ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128, 62)"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(seg_flip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1., -1.,  1.,  1.])"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.append(a,[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nibabel.nifti1.Nifti1Header'> object, endian='<'\n",
      "sizeof_hdr      : 348\n",
      "data_type       : 32\n",
      "db_name         : \n",
      "extents         : 0\n",
      "session_error   : 0\n",
      "regular         : r\n",
      "dim_info        : 0\n",
      "dim             : [  3 128 128  62   1   1   1   1]\n",
      "intent_p1       : 0.0\n",
      "intent_p2       : 0.0\n",
      "intent_p3       : 0.0\n",
      "intent_code     : none\n",
      "datatype        : uint32\n",
      "bitpix          : 32\n",
      "slice_start     : 0\n",
      "pixdim          : [-1.          2.          2.          1.99999976  1.          0.          0.\n",
      "  0.        ]\n",
      "vox_offset      : 0.0\n",
      "scl_slope       : nan\n",
      "scl_inter       : nan\n",
      "slice_end       : 0\n",
      "slice_code      : unknown\n",
      "xyzt_units      : 10\n",
      "cal_max         : 0.00220409687608\n",
      "cal_min         : 0.0\n",
      "slice_duration  : 0.0\n",
      "toffset         : 0.0\n",
      "glmax           : 0\n",
      "glmin           : 0\n",
      "descrip         : FSL5.0\n",
      "aux_file        : \n",
      "qform_code      : scanner\n",
      "sform_code      : scanner\n",
      "quatern_b       : -0.0235229991376\n",
      "quatern_c       : -0.999443292618\n",
      "quatern_d       : -0.000718155759387\n",
      "qoffset_x       : 120.489822388\n",
      "qoffset_y       : -108.620071411\n",
      "qoffset_z       : -41.6052131653\n",
      "srow_x          : [ -1.99554968e+00   9.41075459e-02   9.44717824e-02   1.20489822e+02]\n",
      "srow_y          : [  9.39716771e-02   1.99778461e+00  -5.09611191e-03  -1.08620071e+02]\n",
      "srow_z          : [  9.46069360e-02   6.45936525e-04   1.99776065e+00  -4.16052132e+01]\n",
      "intent_name     : \n",
      "magic           : n+1\n"
     ]
    }
   ],
   "source": [
    "img3=nb.load('/home/chris/Documents/projects_working/2016_Brainhack/DWI_sample/CIC_dti_FA_seg_cjs.nii.gz')\n",
    "print(img3.header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#FAseg[1][2,2]=FAseg[1][2,2]*-1\n",
    "#img=nb.Nifti1Image(seg,cbs.flip_affine_orientation(FAseg[1],flipLR=False,flipAP=True)\n",
    "#img.set_data_dtype('uint32')\n",
    "#newq=img.get_qform()[2,2]*img.get_qform\n",
    "#img.set_qform(newq)\n",
    "#img.to_filename(join(in_dir,\"test.nii.gz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newq=img.get_qform()\n",
    "newq[2,2]=img.get_qform()[2,2]*-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb.apply_orientation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('L', 'P', 'S'), 'AXIAL')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbs.get_affine_orientation_slice(nb.load(join(data_dir,uni_fname)).affine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nibabel.nifti1.Nifti1Header'> object, endian='>'\n",
      "sizeof_hdr      : 348\n",
      "data_type       : \n",
      "db_name         : uni_stripped.nii\n",
      "extents         : 0\n",
      "session_error   : 0\n",
      "regular         : r\n",
      "dim_info        : 0\n",
      "dim             : [  3 146 174 146   1   1   1   1]\n",
      "intent_p1       : 0.0\n",
      "intent_p2       : 0.0\n",
      "intent_p3       : 0.0\n",
      "intent_code     : none\n",
      "datatype        : complex64\n",
      "bitpix          : 32\n",
      "slice_start     : 0\n",
      "pixdim          : [ 1.          1.24657536  1.25114942  1.24657536  0.          0.          0.\n",
      "  0.        ]\n",
      "vox_offset      : 0.0\n",
      "scl_slope       : nan\n",
      "scl_inter       : nan\n",
      "slice_end       : 0\n",
      "slice_code      : unknown\n",
      "xyzt_units      : 10\n",
      "cal_max         : 0.0\n",
      "cal_min         : 0.0\n",
      "slice_duration  : 0.0\n",
      "toffset         : 0.0\n",
      "glmax           : 4096\n",
      "glmin           : 0\n",
      "descrip         : Unknown Modality\n",
      "aux_file        :  \n",
      "qform_code      : scanner\n",
      "sform_code      : unknown\n",
      "quatern_b       : 0.0\n",
      "quatern_c       : 0.0\n",
      "quatern_d       : 1.0\n",
      "qoffset_x       : 107.212188721\n",
      "qoffset_y       : 182.943893433\n",
      "qoffset_z       : -230.70652771\n",
      "srow_x          : [ 0.  0.  0.  0.]\n",
      "srow_y          : [ 0.  0.  0.  0.]\n",
      "srow_z          : [ 0.  0.  0.  0.]\n",
      "intent_name     : \n",
      "magic           : n+1\n"
     ]
    }
   ],
   "source": [
    "#cbs.recursively_generate_group_intensity_priors(seg_iterations=0)\n",
    "na=nb.load(join(data_dir,uni_fname)).header\n",
    "na['datatype'] = np.array(32).astype('uint32')\n",
    "print(na)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
